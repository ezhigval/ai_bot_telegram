## core — Python-ядро персонального ИИ

Этот подпроект будет содержать HTTP/WebSocket-сервис ядра:

- обработка сообщений от клиентов (Telegram, macOS-клиент);
- интеграция с локальными LLM (через Ollama/llama.cpp и аналоги);
- память и персонализация пользователя;
- вызов инструментов (web-поиск, файлы, медиа и т.д.).

Запуск и стек (черновик, для Agent Core/LLM):

- Python 3.11+;
- FastAPI (или аналогичный async-фреймворк);
- uvicorn для локального запуска;
- pydantic для описания моделей запросов/ответов.

Ядро должно поднимать минимум такие endpoint’ы:

- `POST /v1/messages` — приём сообщения (текст/файл/медиа) и возврат ответа;
- `GET /v1/history` — получение истории диалогов;
- `GET /v1/profile` / `PATCH /v1/profile` — работа с профилем пользователя.


